{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2275ea78-5218-4ab5-b7c3-425cd17890ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (2.32.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2024.6.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2299a13-c325-4684-9570-d0d1a16bc745",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5414580-0f8b-48c6-a160-a905b6191538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hugging Face Model Endpoint\n",
    "API_URL = \"https://api-inference.huggingface.co/models/Jean-Baptiste/roberta-large-ner-english\"\n",
    "\n",
    "# ðŸ” Replace with your Hugging Face API Token\n",
    "HUGGINGFACE_API_TOKEN = \"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\"\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {HUGGINGFACE_API_TOKEN}\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c4e65b96-a236-4805-a1ff-bab6fe9229ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_name_from_resume(text):\n",
    "    text = text[:100]  # Take only the first 50 characters\n",
    "\n",
    "    payload = {\"inputs\": text}\n",
    "    response = requests.post(API_URL, headers=headers, json=payload)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(\"Error:\", response.status_code, response.text)\n",
    "        return None\n",
    "\n",
    "    result = response.json()\n",
    "\n",
    "    current_name = []\n",
    "    total_length = 0\n",
    "\n",
    "    for entity in result:\n",
    "        if entity.get(\"entity_group\") == \"PER\":\n",
    "            word = entity[\"word\"]\n",
    "            if word.startswith(\"Ä \"):  # handle subword prefix\n",
    "                word = word[1:]\n",
    "\n",
    "            additional_length = len(word) + (1 if current_name else 0)\n",
    "            if total_length + additional_length > 20:\n",
    "                break\n",
    "\n",
    "            current_name.append(word)\n",
    "            total_length += additional_length\n",
    "        elif current_name:\n",
    "            break  # Stop after the first full name ends\n",
    "\n",
    "    return \" \".join(current_name) if current_name else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a9d2f921-d14a-4d17-81ce-81e6bd732945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Names:\n",
      " kinjalkanjilal"
     ]
    }
   ],
   "source": [
    "sample_text = \"\"\"\n",
    "\n",
    "KINJAL KANJILAL Address: Phone: Email: 54/2 Suresh Chandra Pal Road, Naihati +91 6290201761 kinjalkanjilal333@gmail.com SUMMARY EDUCATION AI-driven Machine Learning and Data Science professional with a strong track record in developing and deploying end-to-end, production-ready solutions. Expertise spans advanced ML/DL algorithms, MLOps practices, and scalable data pipelines. Proficient in Python, cloud platforms, Docker, and orchestration tools like MLflow, DVC, and Airflow. Experienced in building intelligent agentic A.I systems. Combines technical depth with a results-focused mindset to drive innovation, optimize performance, and deliver impactful, data-driven outcomes. Bachelor of Technology in Computer Science Engineering (AIML) Heritage Institute of Technology, Kolkata Class XII ISC (CISCE BOARD) St. Luke's Day School, Naihati, Kolkata Class X ICSE (CISCE BOARD) St. Luke's Day School, Naihati, Kolkata EXPERIENCE October 2021 - June 2025 Graduated: 2021 Graduated: 2019 Data Science intern at UN IT ERP Academy (2 September 2024 - 15 December 2024) nd th Built a RAG-based SQL Query Editor during internship using LangChain, OpenAI API, and Streamlit, where user questions are rephrased into accurate SQL queries and executed to display results dynamically. SKILLS AND CERTIFICATIONS Technical Skills: Python, Machine Learning (ML) & Deep Learning (DL), SQL and DBMS, MLOps â€“ MLFlow, DVC, Model Lifecycle Management, Git & Version Control, Docker & Containerization, Cloud Technologies for Data Science â€“ AWS (Lambda, S3, Bedrock, SageMaker), Data Analysis, Natural Language Processing (NLP) & Computer Vision, Building Efficient AI Agents, Apache Airflow, Grafana (for cloud-based model monitoring), Dagshub (LLMOps & experiment tracking). Certifications: Alphabetz Digital Academy (basics of AIML), AWS certification for Solutions Architecture Job Simulation at Forage, Risk Job Simulation for Goldman Sachs at Forage, Tata Group Data Visualisation: Empowering Business with Effective Insights Completion Certificate, Complete MLOps Bootcamp Certification by  on Udemy. PROJECTS Plant Disease Detection Web App Using Transfer Learning and Fine-Tuned CNN Models (Final Year Project) Developed a Plant Disease Detection web app using Flask, HTML, CSS, and JavaScript, implemented in Python with Keras and pretrained VGG16 model from ImageNet, and integrated the DeepSeek R1 model locally for disease summarization. SENTIMENT ANALYSIS WEB APP FOR A HOTELIER USING MACHINE LEARNING Developed a sentiment analysis web app for a hotelier using machine learning to classify customer reviews as positive or negative. NASA APOD ETL Pipeline with Apache Airflow and PostgreSQL Designed and implemented an ETL pipeline using Apache Airflow to automate the extraction of NASAâ€™s Astronomy Picture of the Day (APOD) data, transform the metadata, and load it into a PostgreSQL database for structured storage and analysis. Customer Churn Prediction and RFM Analysis Using Deep Learning Conducted data analytics to uncover customer behavior patterns through RFM (Recency, Frequency, Monetary) analysis and interactive visualizations. Built a deep learning model to predict customer churn, enabling proactive retention strategies based on behavioral insights. Agentic AI: Intelligent Agent System with RAG and Real-Time Data Integration Created an Agentic AI system from scratch using LangChain and RAG, integrating Wikipedia and ReadFile for real-time data retrieval and context-aware responses, with seamless extension for additional APIs and OpenAI model integration. AWS Lambda Blog Generator Using Amazon Bedrock and S3 Storage Developed a serverless blog generation app using AWS Lambda, Amazon Bedrockâ€™s Meta LLaMA3-70B, and API Gateway to automatically generate 200-word blogs and save them in an S3 bucket with dynamic file naming. LANGUAGES AND HOBBIES Languages - English, Bengali, Hindi Hobbies - Bike Riding, Photography, Fitness, Crypto and Stock Market Analysis\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "names = extract_names_from_text(sample_text.lower())\n",
    "print(\"Extracted Names:\")\n",
    "count=0\n",
    "for char in names[0]:\n",
    "    count+=1\n",
    "    if count < 18:\n",
    "        print(char,end=\"\")\n",
    "    else:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aea0ffd-efd7-4282-964b-9bacd5d16675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9918c166-3f74-480d-b30c-436b13d522a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
