âœ… 1. Use a Pretrained API to Infer Names from Text
(Example: Bedrock amazon nova pro model)

ğŸ”· Pros:
âœ… No deployment hassle (no large models in Lambda)

âœ… Faster development, no packaging nightmare

âœ… Always access to updated models

âœ… Can scale independently of your Lambda

ğŸ”´ Cons:
âŒ Requires external network calls (slightly slower per call)

âŒ Dependent on third-party APIs or uptime

âŒ May have cost/usage limits (if using hosted inference APIs)

âœ… 2. Fine-tune and Deploy Model inside AWS Lambda
(Example: custom spaCy or HuggingFace model zipped and used inside Lambda)

ğŸ”· Pros:
âœ… Fully offline and self-contained

âœ… Custom-trained for your resume format â†’ higher accuracy

âœ… No external latency or dependency

ğŸ”´ Cons:
âŒ Lambda storage limit = 250 MB unzipped (HuggingFace BERT = 400+ MB) â†’ spaCy may work with compression

âŒ Cold starts + slow inference if not optimized

âŒ Difficult to package all dependencies (e.g. torch, transformers) with native binaries